{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sparks-baird/self-driving-lab-demo/blob/main/notebooks/6.2.1-multi-fidelity-continuous.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continous Multi-fidelity Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For notebook gallery thumbnail\n",
    "if IN_COLAB:\n",
    "    from IPython.display import Image\n",
    "    Image(filename=\"continuous-multi-fidelity.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In [the previous notebook](https://colab.research.google.com/github/sparks-baird/self-driving-lab-demo/blob/main/notebooks/6.2-multi-fidelity.ipynb), I provided a brief introduction of multi-fidelity\n",
    "optimization in the context of the physical sciences. This notebook will cover\n",
    "Bayesian optimization using two continuous fidelity parameters (`atime` and `astep`). We'll compare the total integration time using the\n",
    "multi-fidelity optimization with the integration time costs of running the simulation at the\n",
    "the lowest fidelities, the highest fidelities (default), and approximately halfway in-between. For validation, the\n",
    "objective (in this case, `frechet`) will be evaluated at the upper bound of `atime` and `astep`. In\n",
    "this experiment, we'll allow `atime` to vary between `0..100` (upper limit is 255) which is:\n",
    "$2.78 \\mu s .. 280.78\\mu s$. Since multiple fidelity parameters [aren't yet supported\n",
    "with Ax](https://github.com/facebook/Ax/issues/1211) (i.e. requires using BoTorch directly), we'll fix `astep` to `999` (limits are `0..65534`). In terms\n",
    "of physical integration time, this corresponds to lowest and highest integration times\n",
    "of $278 \\mu s$ and $281 ms$, respectively.\n",
    "\n",
    "For reference, here are the docs for `atime` and `astep` (taken from [`public_mqtt_sdl_demo/lib/as7341_sensor.py`](https://github.com/sparks-baird/self-driving-lab-demo/blob/main/src/public_mqtt_sdl_demo/lib/as7341_sensor.py)):\n",
    "```python\n",
    "\"\"\"\n",
    "...\n",
    "atime : int, optional\n",
    "    The integration time step size in 2.78 microsecond increments, by default 100\n",
    "astep : int, optional\n",
    "    The integration time step count. Total integration time will be (ATIME + 1)\n",
    "    * (ASTEP + 1) * 2.78µS, by default 999, meaning 281 ms assuming atime=100\n",
    "...\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "We'll be using the Knowledge Gradient (KG) acquisition function. \n",
    "\n",
    "From [the BoTorch docs](https://botorch.org/tutorials/one_shot_kg):\n",
    "> ### The one-shot Knowledge Gradient acquisition function\n",
    "> The Knowledge Gradient (KG) (see [2, 3]) is a look-ahead acquisition function that quantifies the expected increase in the maximum of the modeled black-box function f from obtaining additional (random) observations collected at the candidate set x. KG often shows improved Bayesian Optimization performance relative to simpler acquisition functions such as Expected Improvement, but in its traditional form it is computationally expensive and hard to implement.\n",
    ">\n",
    "> ...\n",
    "> \n",
    "> [2] P. Frazier, W. Powell, and S. Dayanik. A Knowledge-Gradient policy for sequential information collection. SIAM Journal on Control and Optimization, 2008.\n",
    "> \n",
    "> [3] J. Wu and P. Frazier. The parallel knowledge gradient method for batch bayesian optimization. NIPS 2016.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll still use Ax rather than delving into pure BoTorch code. Since\n",
    "Ax doesn't yet support discrete fidelity parameters, for the next notebook, we'll use\n",
    "BoTorch exclusively. BoTorch has [a tutorial for continuous multi-fidelity optimization](https://botorch.org/tutorials/multi_fidelity_bo#Multi-Fidelity-BO-in-BoTorch-with-Knowledge-Gradient)\n",
    "which has been [adapted for Ax in a GitHub\n",
    "issue](https://github.com/facebook/Ax/issues/475). We will largely base the\n",
    "implementation on the example from the GitHub issue."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we need to set up our `SelfDrivingLabDemo` classes. We will use the\n",
    "physical experimental setting since the simulations use only a simple multiplier to account for\n",
    "integration time. We'll also use the same `frechet` objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    %pip install self-driving-lab-demo[ax-platform]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session ID: f0d33d7d-c270-474f-a45a-e5873c994745\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4  # universally unique identifier\n",
    "from self_driving_lab_demo import SelfDrivingLabDemoLight, mqtt_observe_sensor_data\n",
    "\n",
    "dummy = True  # @param {type:\"boolean\"}\n",
    "pico_id = \"test\"  # @param {type:\"string\"}\n",
    "log_to_mongodb = False  # speed up the evaluation\n",
    "if dummy:\n",
    "    num_repeats = 2\n",
    "    atime_max = 5\n",
    "    astep_max = 5\n",
    "    time_limit_multiplier = 1\n",
    "else:\n",
    "    num_repeats = 5  # @param {type:\"integer\"}\n",
    "    atime_max = 100\n",
    "    astep_max = 999  # fixed for now (see note above)\n",
    "    time_limit_multiplier = 10  # @param {type:\"number\"}\n",
    "\n",
    "model_gen_kwargs = (\n",
    "    dict(num_fantasies=2, num_restarts=2, raw_samples=8) if dummy else None\n",
    ")\n",
    "\n",
    "simulation = False  # @param {type:\"boolean\"}\n",
    "SESSION_ID = str(uuid4())  # random session ID\n",
    "\n",
    "\n",
    "def calc_integration_time_s(atime, astep):\n",
    "    \"\"\"\n",
    "    Calculate integration time (i.e., time cost) of light sensor.\n",
    "\n",
    "    atime : int, optional\n",
    "    The integration time step size in 2.78 microsecond increments, by default 100\n",
    "    astep : int, optional\n",
    "        The integration time step count. Total integration time will be (ATIME + 1)\n",
    "        * (ASTEP + 1) * 2.78µS, by default 999, meaning 281 ms assuming atime=100\n",
    "    \"\"\"\n",
    "    return ((atime + 1) * (astep + 1) * 2.78) / 1e6\n",
    "\n",
    "\n",
    "# total seconds of integration time\n",
    "time_limit_s = time_limit_multiplier * calc_integration_time_s(atime_max, astep_max)\n",
    "seeds = range(10, 10 + num_repeats)\n",
    "print(f\"session ID: {SESSION_ID}\")\n",
    "\n",
    "sdls = [\n",
    "    SelfDrivingLabDemoLight(\n",
    "        autoload=True,  # perform target data experiment automatically\n",
    "        simulation=simulation,\n",
    "        observe_sensor_data_fn=mqtt_observe_sensor_data,  # (default)\n",
    "        observe_sensor_data_kwargs=dict(\n",
    "            pico_id=pico_id, session_id=SESSION_ID, mongodb=log_to_mongodb\n",
    "        ),\n",
    "        target_seed=seed,\n",
    "    )\n",
    "    for seed in seeds\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'R', 'type': 'range', 'bounds': [0, 89]},\n",
       " {'name': 'G', 'type': 'range', 'bounds': [0, 89]},\n",
       " {'name': 'B', 'type': 'range', 'bounds': [0, 89]},\n",
       " {'name': 'atime',\n",
       "  'type': 'range',\n",
       "  'is_fidelity': True,\n",
       "  'bounds': [0, 5],\n",
       "  'target_value': 5},\n",
       " {'name': 'astep', 'type': 'fixed', 'value': 5}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = dict(R=sdls[0].bounds[\"R\"], G=sdls[0].bounds[\"G\"], B=sdls[0].bounds[\"B\"])\n",
    "params = [dict(name=nm, type=\"range\", bounds=bnd) for nm, bnd in bounds.items()]\n",
    "atime_bnd = [0, atime_max]  # instead of [0, 255]\n",
    "astep_bnd = [0, astep_max]  # instead of [0, 65534]\n",
    "params.append(\n",
    "    dict(\n",
    "        name=\"atime\",\n",
    "        type=\"range\",\n",
    "        is_fidelity=True,\n",
    "        bounds=atime_bnd,\n",
    "        target_value=atime_bnd[1],\n",
    "    )\n",
    ")\n",
    "params.append(\n",
    "    dict(\n",
    "        name=\"astep\",\n",
    "        type=\"fixed\",\n",
    "        value=astep_max,\n",
    "    )\n",
    ")\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 08-09 18:37:54] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 6 decimal points.\n",
      "[INFO 08-09 18:37:54] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter R. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 08-09 18:37:54] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter G. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 08-09 18:37:54] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter B. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 08-09 18:37:54] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter atime. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 08-09 18:37:54] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='R', parameter_type=INT, range=[0, 89]), RangeParameter(name='G', parameter_type=INT, range=[0, 89]), RangeParameter(name='B', parameter_type=INT, range=[0, 89]), RangeParameter(name='atime', parameter_type=INT, range=[0, 5], fidelity=True, target_value=5), FixedParameter(name='astep', parameter_type=INT, value=5)], parameter_constraints=[]).\n",
      "[INFO 08-09 18:37:54] ax.service.ax_client: Generated new trial 0 with parameters {'R': 76, 'G': 50, 'B': 25, 'atime': 0, 'astep': 5}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_kwargs: {'torch_device': device(type='cuda')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 08-09 18:37:57] ax.service.ax_client: Completed trial 0 with data: {'model_runtime_s': (0.008999, None), 'frechet': (15568.0, None)}.\n",
      "[INFO 08-09 18:37:57] ax.service.ax_client: Generated new trial 1 with parameters {'R': 82, 'G': 58, 'B': 18, 'atime': 5, 'astep': 5}.\n",
      "[INFO 08-09 18:38:01] ax.service.ax_client: Completed trial 1 with data: {'model_runtime_s': (0.015611, None), 'frechet': (15568.0, None)}.\n",
      "[INFO 08-09 18:38:01] ax.service.ax_client: Generated new trial 2 with parameters {'R': 55, 'G': 3, 'B': 87, 'atime': 4, 'astep': 5}.\n",
      "[INFO 08-09 18:38:04] ax.service.ax_client: Completed trial 2 with data: {'model_runtime_s': (0.006849, None), 'frechet': (15567.0, None)}.\n",
      "[INFO 08-09 18:38:04] ax.service.ax_client: Generated new trial 3 with parameters {'R': 32, 'G': 11, 'B': 18, 'atime': 0, 'astep': 5}.\n",
      "[INFO 08-09 18:38:08] ax.service.ax_client: Completed trial 3 with data: {'model_runtime_s': (0.005571, None), 'frechet': (15568.0, None)}.\n",
      "[INFO 08-09 18:38:08] ax.service.ax_client: Generated new trial 4 with parameters {'R': 10, 'G': 35, 'B': 0, 'atime': 3, 'astep': 5}.\n",
      "[INFO 08-09 18:38:11] ax.service.ax_client: Completed trial 4 with data: {'model_runtime_s': (0.013036, None), 'frechet': (15567.388638, None)}.\n",
      "[INFO 08-09 18:38:11] ax.service.ax_client: Generated new trial 5 with parameters {'R': 42, 'G': 71, 'B': 88, 'atime': 0, 'astep': 5}.\n",
      "[INFO 08-09 18:38:15] ax.service.ax_client: Completed trial 5 with data: {'model_runtime_s': (0.0115, None), 'frechet': (15568.0, None)}.\n",
      "[INFO 08-09 18:39:09] ax.service.ax_client: Generated new trial 6 with parameters {'R': 79, 'G': 0, 'B': 89, 'atime': 0, 'astep': 5}.\n",
      "[INFO 08-09 18:39:12] ax.service.ax_client: Completed trial 6 with data: {'model_runtime_s': (53.845453, None), 'frechet': (15568.0, None)}.\n",
      "[INFO 08-09 18:40:16] ax.service.ax_client: Generated new trial 7 with parameters {'R': 36, 'G': 0, 'B': 89, 'atime': 0, 'astep': 5}.\n",
      "[INFO 08-09 18:40:19] ax.service.ax_client: Completed trial 7 with data: {'model_runtime_s': (63.513963, None), 'frechet': (15565.0, None)}.\n",
      "[INFO 08-09 18:41:28] ax.service.ax_client: Generated new trial 8 with parameters {'R': 16, 'G': 0, 'B': 89, 'atime': 0, 'astep': 5}.\n",
      "[INFO 08-09 18:41:32] ax.service.ax_client: Completed trial 8 with data: {'model_runtime_s': (68.218229, None), 'frechet': (15567.157383, None)}.\n",
      "[INFO 08-09 18:42:42] ax.service.ax_client: Generated new trial 9 with parameters {'R': 34, 'G': 0, 'B': 69, 'atime': 5, 'astep': 5}.\n",
      "[INFO 08-09 18:42:45] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 6 decimal points.\n",
      "[INFO 08-09 18:42:45] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter R. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 08-09 18:42:45] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter G. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 08-09 18:42:45] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter B. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 08-09 18:42:45] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter atime. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 08-09 18:42:45] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='R', parameter_type=INT, range=[0, 89]), RangeParameter(name='G', parameter_type=INT, range=[0, 89]), RangeParameter(name='B', parameter_type=INT, range=[0, 89]), RangeParameter(name='atime', parameter_type=INT, range=[0, 5], fidelity=True, target_value=5), FixedParameter(name='astep', parameter_type=INT, value=5)], parameter_constraints=[]).\n",
      "[INFO 08-09 18:42:45] ax.service.ax_client: Generated new trial 0 with parameters {'R': 22, 'G': 69, 'B': 63, 'atime': 0, 'astep': 5}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time limit reached: 0.00010008 s\n",
      "Running integration time 5.004e-05 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 08-09 18:42:48] ax.service.ax_client: Completed trial 0 with data: {'model_runtime_s': (0.0, None), 'frechet': (9536.179791, None)}.\n",
      "[INFO 08-09 18:42:48] ax.service.ax_client: Generated new trial 1 with parameters {'R': 1, 'G': 59, 'B': 25, 'atime': 3, 'astep': 5}.\n",
      "[INFO 08-09 18:42:52] ax.service.ax_client: Completed trial 1 with data: {'model_runtime_s': (0.015429, None), 'frechet': (9537.335529, None)}.\n",
      "[INFO 08-09 18:42:52] ax.service.ax_client: Generated new trial 2 with parameters {'R': 79, 'G': 47, 'B': 76, 'atime': 2, 'astep': 5}.\n",
      "[INFO 08-09 18:42:55] ax.service.ax_client: Completed trial 2 with data: {'model_runtime_s': (0.00596, None), 'frechet': (9530.180533, None)}.\n",
      "[INFO 08-09 18:42:55] ax.service.ax_client: Generated new trial 3 with parameters {'R': 26, 'G': 5, 'B': 84, 'atime': 5, 'astep': 5}.\n",
      "[INFO 08-09 18:42:59] ax.service.ax_client: Completed trial 3 with data: {'model_runtime_s': (0.013637, None), 'frechet': (9533.180162, None)}.\n",
      "[INFO 08-09 18:42:59] ax.service.ax_client: Generated new trial 4 with parameters {'R': 24, 'G': 26, 'B': 46, 'atime': 2, 'astep': 5}.\n",
      "[INFO 08-09 18:43:02] ax.service.ax_client: Completed trial 4 with data: {'model_runtime_s': (0.008964, None), 'frechet': (9533.047204, None)}.\n",
      "[INFO 08-09 18:43:02] ax.service.ax_client: Generated new trial 5 with parameters {'R': 14, 'G': 5, 'B': 35, 'atime': 5, 'astep': 5}.\n",
      "[INFO 08-09 18:43:05] ax.service.ax_client: Completed trial 5 with data: {'model_runtime_s': (0.008964, None), 'frechet': (9537.335529, None)}.\n",
      "[INFO 08-09 18:44:10] ax.service.ax_client: Generated new trial 6 with parameters {'R': 74, 'G': 20, 'B': 83, 'atime': 0, 'astep': 5}.\n",
      "[INFO 08-09 18:44:14] ax.service.ax_client: Completed trial 6 with data: {'model_runtime_s': (64.559284, None), 'frechet': (9535.0, None)}.\n",
      "[INFO 08-09 18:45:14] ax.service.ax_client: Generated new trial 7 with parameters {'R': 89, 'G': 66, 'B': 88, 'atime': 0, 'astep': 5}.\n",
      "[INFO 08-09 18:45:17] ax.service.ax_client: Completed trial 7 with data: {'model_runtime_s': (60.053519, None), 'frechet': (9534.047199, None)}.\n",
      "[INFO 08-09 18:46:21] ax.service.ax_client: Generated new trial 8 with parameters {'R': 86, 'G': 48, 'B': 50, 'atime': 0, 'astep': 5}.\n",
      "[INFO 08-09 18:46:24] ax.service.ax_client: Completed trial 8 with data: {'model_runtime_s': (63.737873, None), 'frechet': (9534.047199, None)}.\n",
      "[INFO 08-09 18:47:13] ax.service.ax_client: Generated new trial 9 with parameters {'R': 56, 'G': 50, 'B': 82, 'atime': 0, 'astep': 5}.\n",
      "[INFO 08-09 18:47:17] ax.service.ax_client: Completed trial 9 with data: {'model_runtime_s': (49.075867, None), 'frechet': (9538.0, None)}.\n",
      "[INFO 08-09 18:48:25] ax.service.ax_client: Generated new trial 10 with parameters {'R': 89, 'G': 34, 'B': 89, 'atime': 0, 'astep': 5}.\n",
      "[INFO 08-09 18:48:29] ax.service.ax_client: Completed trial 10 with data: {'model_runtime_s': (67.872802, None), 'frechet': (9538.0, None)}.\n",
      "[INFO 08-09 18:49:26] ax.service.ax_client: Generated new trial 11 with parameters {'R': 89, 'G': 81, 'B': 59, 'atime': 0, 'astep': 5}.\n",
      "[INFO 08-09 18:49:29] ax.service.ax_client: Completed trial 11 with data: {'model_runtime_s': (57.316357, None), 'frechet': (9536.179791, None)}.\n",
      "[INFO 08-09 18:50:28] ax.service.ax_client: Generated new trial 12 with parameters {'R': 74, 'G': 27, 'B': 39, 'atime': 0, 'astep': 5}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time limit reached: 0.00010008 s\n",
      "Running integration time 0.00010007999999999999 s\n"
     ]
    }
   ],
   "source": [
    "from ax.service.ax_client import AxClient\n",
    "from ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n",
    "from ax.modelbridge.registry import Models\n",
    "from ax.service.utils.instantiation import ObjectiveProperties\n",
    "import torch\n",
    "from time import time\n",
    "\n",
    "integration_time_name = \"integration_time_s\"\n",
    "model_runtime_name = \"model_runtime_s\"\n",
    "tracking_metric_names = [integration_time_name, model_runtime_name]\n",
    "\n",
    "campaign_objects = []\n",
    "objective_name = \"frechet\"\n",
    "batch_size = 1\n",
    "num_sobol = 6\n",
    "objectives = {objective_name: ObjectiveProperties(minimize=True)}\n",
    "model_kwargs = (\n",
    "    {\"torch_device\": torch.device(\"cuda\")} if torch.cuda.is_available() else None\n",
    ")\n",
    "print(f\"model_kwargs: {model_kwargs}\")\n",
    "\n",
    "for i, sdl in enumerate(sdls):\n",
    "\n",
    "    def evaluate(parameters):\n",
    "        results = sdl.evaluate(parameters)\n",
    "        # # remove channel names to prevent extra tracking metrics warnings\n",
    "        # [results.pop(ch) for ch in sdl.channel_names]\n",
    "        atime = parameters[\"atime\"]\n",
    "        astep = parameters[\"astep\"]\n",
    "        results[integration_time_name] = calc_integration_time_s(atime, astep)\n",
    "        return {objective_name: results[objective_name]}\n",
    "\n",
    "    gs = GenerationStrategy(\n",
    "        steps=[\n",
    "            GenerationStep(model=Models.SOBOL, num_trials=num_sobol),\n",
    "            GenerationStep(\n",
    "                model=Models.GPKG,\n",
    "                num_trials=-1,\n",
    "                model_kwargs=model_kwargs,\n",
    "                model_gen_kwargs=model_gen_kwargs,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ax_client = AxClient(generation_strategy=gs)\n",
    "    ax_client.create_experiment(\n",
    "        name=\"sdl_demo_mf_experiment\",\n",
    "        parameters=params,\n",
    "        objectives=objectives,\n",
    "        tracking_metric_names=tracking_metric_names,\n",
    "        overwrite_existing_experiment=True,\n",
    "    )\n",
    "\n",
    "    running_integration_time_s = 0\n",
    "    # Initial sobol samples\n",
    "    for i in range(num_sobol):\n",
    "        t0 = time()\n",
    "        parameters, trial_index = ax_client.get_next_trial()\n",
    "        model_runtime_dict = {model_runtime_name: time() - t0}\n",
    "        results = evaluate(parameters)\n",
    "        raw_data = {**model_runtime_dict, **results}\n",
    "        ax_client.complete_trial(trial_index=trial_index, raw_data=raw_data)\n",
    "\n",
    "    # KGBO\n",
    "    while running_integration_time_s < time_limit_s:\n",
    "        t0 = time()\n",
    "        q_p, q_t = [], []\n",
    "        # Simulate batches\n",
    "        for q in range(batch_size):\n",
    "            parameters, trial_index = ax_client.get_next_trial()\n",
    "            q_p.append(parameters)\n",
    "            q_t.append(trial_index)\n",
    "        model_runtime_dict = {model_runtime_name: time() - t0}\n",
    "\n",
    "        for q in range(batch_size):\n",
    "            pi = q_p[q]\n",
    "            ti = q_t[q]\n",
    "            integration_time = calc_integration_time_s(pi[\"atime\"], pi[\"astep\"])\n",
    "            running_integration_time_s = running_integration_time_s + integration_time\n",
    "            results = evaluate(pi)\n",
    "            if running_integration_time_s > time_limit_s:\n",
    "                # backup the time by one iteration and break\n",
    "                final_cost_s = running_integration_time_s - integration_time\n",
    "                break\n",
    "            raw_data = {**model_runtime_dict, **results}\n",
    "            ax_client.complete_trial(trial_index=ti, raw_data=raw_data)\n",
    "\n",
    "    print(f\"Time limit reached: {time_limit_s} s\")\n",
    "    print(f\"Running integration time {final_cost_s} s\")\n",
    "\n",
    "    campaign_objects.append({\"campaign_num\": i, \"sdl\": sdl, \"ax_client\": ax_client})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00011675999999999999"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_integration_time_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AxClient(experiment=Experiment(sdl_demo_mf_experiment)),\n",
       " AxClient(experiment=Experiment(sdl_demo_mf_experiment)),\n",
       " AxClient(experiment=Experiment(sdl_demo_mf_experiment)),\n",
       " AxClient(experiment=Experiment(sdl_demo_mf_experiment)),\n",
       " AxClient(experiment=Experiment(sdl_demo_mf_experiment))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params.append(\n",
    "#     dict(\n",
    "#         name=\"astep\",\n",
    "#         type=\"range\",\n",
    "#         is_fidelity=True,\n",
    "#         bounds=astep_bnd,\n",
    "#         target_value=astep_bnd[1],\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from botorch.test_functions.multi_fidelity import AugmentedHartmann\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [\n",
    "#     \"utc_timestamp\",\n",
    "#     \"ch470\",\n",
    "#     \"ch550\",\n",
    "#     \"ch670\",\n",
    "#     \"ch410\",\n",
    "#     \"background\", # needs to be collapsed\n",
    "#     \"ch620\",\n",
    "#     \"sd_card_ready\",\n",
    "#     \"ch510\",\n",
    "#     \"warning\",\n",
    "#     \"ch583\",\n",
    "#     \"device_nickname\",\n",
    "#     \"ch440\",\n",
    "#     \"onboard_temperature_K\",\n",
    "#     \"encrypted_device_id_truncated\",\n",
    "#     \"mae\",\n",
    "#     \"rmse\",\n",
    "#     \"frechet\",\n",
    "# ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sdl-demo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70cb6d4911b67e25d1487ebd620c5d1370239efaaf47f3851af44f5c5a26f988"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
