{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will load a dataset from `scikit-learn` and use it to create a custom `Dataset` object in _Olympus_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: olymp in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (0.0.1b0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from olymp) (1.23.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from olymp) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from pandas->olymp) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from pandas->olymp) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->olymp) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting silence_tensorflow\n",
      "  Downloading silence_tensorflow-1.2.1.tar.gz (3.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.11.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow_probability\n",
      "  Downloading tensorflow_probability-0.19.0-py2.py3-none-any.whl (6.7 MB)\n",
      "     ---------------------------------------- 6.7/6.7 MB 14.3 MB/s eta 0:00:00\n",
      "Collecting support_developer\n",
      "  Downloading support_developer-1.0.5.tar.gz (4.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Using cached tensorflow_intel-2.11.0-cp39-cp39-win_amd64.whl (266.3 MB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.23.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.7.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Using cached tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.43.0)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-15.0.6.1-py2.py3-none-win_amd64.whl (23.2 MB)\n",
      "     --------------------------------------- 23.2/23.2 MB 14.9 MB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.29.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 15.9 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.1.4-py2.py3-none-any.whl (26 kB)\n",
      "Collecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp39-cp39-win_amd64.whl (101 kB)\n",
      "     -------------------------------------- 101.5/101.5 kB 5.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: decorator in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from tensorflow_probability) (5.1.1)\n",
      "Collecting cloudpickle>=1.3\n",
      "  Using cached cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\n",
      "     -------------------------------------- 177.8/177.8 kB 5.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\sterg\\miniconda3\\envs\\sdl-demo\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.8.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: silence_tensorflow, support_developer\n",
      "  Building wheel for silence_tensorflow (setup.py): started\n",
      "  Building wheel for silence_tensorflow (setup.py): finished with status 'done'\n",
      "  Created wheel for silence_tensorflow: filename=silence_tensorflow-1.2.1-py3-none-any.whl size=4466 sha256=6ac98b9531e476e962684f17338392726d5ce4c99686b5b471cc67ec71c5ed0f\n",
      "  Stored in directory: c:\\users\\sterg\\appdata\\local\\pip\\cache\\wheels\\d6\\ec\\29\\1ed23ae577b310931b534a6da0aa3adc169deef9a8ef10bd26\n",
      "  Building wheel for support_developer (setup.py): started\n",
      "  Building wheel for support_developer (setup.py): finished with status 'done'\n",
      "  Created wheel for support_developer: filename=support_developer-1.0.5-py3-none-any.whl size=5630 sha256=c5ec1d57f212061b04bf1837b9e1fe1c319b39616defe4f20dd887f52bd8a895\n",
      "  Stored in directory: c:\\users\\sterg\\appdata\\local\\pip\\cache\\wheels\\7c\\a1\\b1\\9662c79502c353ff7e71c36f84846acd623cbcbe3f7255f5d5\n",
      "Successfully built silence_tensorflow support_developer\n",
      "Installing collected packages: tensorboard-plugin-wit, support_developer, pyasn1, libclang, flatbuffers, dm-tree, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, silence_tensorflow, rsa, pyasn1-modules, protobuf, oauthlib, keras, h5py, google-pasta, gast, cloudpickle, cachetools, astunparse, absl-py, tensorflow_probability, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n",
      "Successfully installed absl-py-1.3.0 astunparse-1.6.3 cachetools-5.2.1 cloudpickle-2.2.0 dm-tree-0.1.8 flatbuffers-23.1.4 gast-0.4.0 google-auth-2.16.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 h5py-3.7.0 keras-2.11.0 libclang-15.0.6.1 markdown-3.4.1 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 silence_tensorflow-1.2.1 support_developer-1.0.5 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.29.0 tensorflow_probability-0.19.0 termcolor-2.2.0 werkzeug-2.2.2 wrapt-1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install olymp\n",
    "%pip install silence_tensorflow tensorflow tensorflow_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;37m[INFO]  ... proceeding with pickle database\n",
      "    [This message will be shown only once]\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\olympus\\plotter\\__init__.py\", line 47, in <module>\n",
      "    import seaborn\n",
      "ModuleNotFoundError: No module named 'seaborn'\n",
      "\u001b[1;33m[WARNING] Plotter requires seaborn, which could not be found.\n",
      "        Please install seaborn to use the plotter\n",
      "    [This message will be shown only once]\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from olympus import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"secrets.json\", \"r\") as f:\n",
    "    secrets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session ID: benchmark-dev-fde4\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "from self_driving_lab_demo import SelfDrivingLabDemoLight, mqtt_observe_sensor_data\n",
    "from self_driving_lab_demo.utils.observe import get_paho_client\n",
    "\n",
    "pico_id = secrets[\"SPARKS_LAB\"]\n",
    "sensor_topic = f\"sdl-demo/picow/{pico_id}/as7341/\"\n",
    "\n",
    "paho_client = get_paho_client(sensor_topic)\n",
    "\n",
    "session_id = f\"benchmark-dev-{str(uuid4())[0:4]}\"\n",
    "print(f\"Session ID: {session_id}\")\n",
    "sdl = SelfDrivingLabDemoLight(\n",
    "    autoload=False,\n",
    "    observe_sensor_data_fn=mqtt_observe_sensor_data,\n",
    "    observe_sensor_data_kwargs=dict(\n",
    "        pico_id=pico_id, session_id=session_id, client=paho_client,\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {\"name\": \"R\", \"type\": \"range\", \"bounds\": [0, 89]},\n",
    "    {\"name\": \"G\", \"type\": \"range\", \"bounds\": [0, 89]},\n",
    "    {\"name\": \"B\", \"type\": \"range\", \"bounds\": [0, 89]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 01-09 19:13:45] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 6 decimal points.\n",
      "[INFO 01-09 19:13:45] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter R. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 01-09 19:13:45] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter G. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 01-09 19:13:45] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter B. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 01-09 19:13:45] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='R', parameter_type=INT, range=[0, 89]), RangeParameter(name='G', parameter_type=INT, range=[0, 89]), RangeParameter(name='B', parameter_type=INT, range=[0, 89])], parameter_constraints=[]).\n",
      "[INFO 01-09 19:13:45] ax.modelbridge.dispatch_utils: Using Bayesian optimization since there are more ordered parameters than there are categories for the unordered categorical parameters.\n",
      "[INFO 01-09 19:13:45] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 6 trials, GPEI for subsequent trials]). Iterations after 6 will take longer to generate due to  model-fitting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'R': 89, 'G': 22, 'B': 36},\n",
       " {'R': 27, 'G': 87, 'B': 84},\n",
       " {'R': 57, 'G': 16, 'B': 1}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ax.service.ax_client import AxClient\n",
    "from ax.modelbridge.factory import get_sobol\n",
    "from random import shuffle\n",
    "\n",
    "num_sobol = 2 ** 7\n",
    "num_repeats = 5\n",
    "\n",
    "client = AxClient()\n",
    "client.create_experiment(parameters=parameters)\n",
    "m = get_sobol(\n",
    "    client.experiment.search_space, seed=10, fallback_to_sample_polytope=True\n",
    ")\n",
    "gr = m.gen(n=num_sobol)\n",
    "sobol_points = [arm.parameters for arm in gr.arms]\n",
    "sobol_points = sobol_points * num_repeats # stays flat\n",
    "shuffle(sobol_points)  # operates inplace\n",
    "sobol_points[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4165e07fdafc4e6aa3c9ea93949ad3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "results = [sdl.observe_sensor_data(point) for point in tqdm(sobol_points)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "savepath = path.join(\n",
    "    \"..\", \"data\", \"processed\", \"olympus-clslab-light-basic-dataset.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>utc_timestamp</th>\n",
       "      <th>background</th>\n",
       "      <th>ch470</th>\n",
       "      <th>ch410</th>\n",
       "      <th>ch440</th>\n",
       "      <th>sd_card_ready</th>\n",
       "      <th>ch510</th>\n",
       "      <th>ch550</th>\n",
       "      <th>ch670</th>\n",
       "      <th>utc_time_str</th>\n",
       "      <th>onboard_temperature_K</th>\n",
       "      <th>encrypted_device_id_truncated</th>\n",
       "      <th>logged_to_mongodb</th>\n",
       "      <th>ch620</th>\n",
       "      <th>device_nickname</th>\n",
       "      <th>ch583</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>1673316830</td>\n",
       "      <td>{'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...</td>\n",
       "      <td>3500</td>\n",
       "      <td>345</td>\n",
       "      <td>4826</td>\n",
       "      <td>True</td>\n",
       "      <td>1380</td>\n",
       "      <td>754</td>\n",
       "      <td>419</td>\n",
       "      <td>2023-1-10 02:13:50</td>\n",
       "      <td>293.6404</td>\n",
       "      <td>6307014457</td>\n",
       "      <td>False</td>\n",
       "      <td>11975</td>\n",
       "      <td>clslab-light-mixing-sparks-lab</td>\n",
       "      <td>7056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>1673316835</td>\n",
       "      <td>{'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...</td>\n",
       "      <td>11106</td>\n",
       "      <td>565</td>\n",
       "      <td>13474</td>\n",
       "      <td>True</td>\n",
       "      <td>8672</td>\n",
       "      <td>1456</td>\n",
       "      <td>822</td>\n",
       "      <td>2023-1-10 02:13:55</td>\n",
       "      <td>294.1085</td>\n",
       "      <td>6307014457</td>\n",
       "      <td>True</td>\n",
       "      <td>2754</td>\n",
       "      <td>clslab-light-mixing-sparks-lab</td>\n",
       "      <td>1710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1673316844</td>\n",
       "      <td>{'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...</td>\n",
       "      <td>1201</td>\n",
       "      <td>140</td>\n",
       "      <td>641</td>\n",
       "      <td>True</td>\n",
       "      <td>773</td>\n",
       "      <td>504</td>\n",
       "      <td>161</td>\n",
       "      <td>2023-1-10 02:14:04</td>\n",
       "      <td>294.1085</td>\n",
       "      <td>6307014457</td>\n",
       "      <td>True</td>\n",
       "      <td>6908</td>\n",
       "      <td>clslab-light-mixing-sparks-lab</td>\n",
       "      <td>4104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>1673316854</td>\n",
       "      <td>{'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...</td>\n",
       "      <td>3822</td>\n",
       "      <td>159</td>\n",
       "      <td>781</td>\n",
       "      <td>True</td>\n",
       "      <td>5996</td>\n",
       "      <td>954</td>\n",
       "      <td>230</td>\n",
       "      <td>2023-1-10 02:14:14</td>\n",
       "      <td>294.1085</td>\n",
       "      <td>6307014457</td>\n",
       "      <td>True</td>\n",
       "      <td>2191</td>\n",
       "      <td>clslab-light-mixing-sparks-lab</td>\n",
       "      <td>1358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>46</td>\n",
       "      <td>72</td>\n",
       "      <td>1673316864</td>\n",
       "      <td>{'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...</td>\n",
       "      <td>7841</td>\n",
       "      <td>500</td>\n",
       "      <td>11260</td>\n",
       "      <td>True</td>\n",
       "      <td>4111</td>\n",
       "      <td>1043</td>\n",
       "      <td>687</td>\n",
       "      <td>2023-1-10 02:14:24</td>\n",
       "      <td>294.1085</td>\n",
       "      <td>6307014457</td>\n",
       "      <td>True</td>\n",
       "      <td>7568</td>\n",
       "      <td>clslab-light-mixing-sparks-lab</td>\n",
       "      <td>4504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R   G   B  utc_timestamp  \\\n",
       "0  89  22  36     1673316830   \n",
       "1  27  87  84     1673316835   \n",
       "2  57  16   1     1673316844   \n",
       "3  26  66   5     1673316854   \n",
       "4  60  46  72     1673316864   \n",
       "\n",
       "                                          background  ch470  ch410  ch440  \\\n",
       "0  {'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...   3500    345   4826   \n",
       "1  {'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...  11106    565  13474   \n",
       "2  {'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...   1201    140    641   \n",
       "3  {'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...   3822    159    781   \n",
       "4  {'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...   7841    500  11260   \n",
       "\n",
       "   sd_card_ready  ch510  ch550  ch670        utc_time_str  \\\n",
       "0           True   1380    754    419  2023-1-10 02:13:50   \n",
       "1           True   8672   1456    822  2023-1-10 02:13:55   \n",
       "2           True    773    504    161  2023-1-10 02:14:04   \n",
       "3           True   5996    954    230  2023-1-10 02:14:14   \n",
       "4           True   4111   1043    687  2023-1-10 02:14:24   \n",
       "\n",
       "   onboard_temperature_K encrypted_device_id_truncated  logged_to_mongodb  \\\n",
       "0               293.6404                    6307014457              False   \n",
       "1               294.1085                    6307014457               True   \n",
       "2               294.1085                    6307014457               True   \n",
       "3               294.1085                    6307014457               True   \n",
       "4               294.1085                    6307014457               True   \n",
       "\n",
       "   ch620                 device_nickname  ch583  \n",
       "0  11975  clslab-light-mixing-sparks-lab   7056  \n",
       "1   2754  clslab-light-mixing-sparks-lab   1710  \n",
       "2   6908  clslab-light-mixing-sparks-lab   4104  \n",
       "3   2191  clslab-light-mixing-sparks-lab   1358  \n",
       "4   7568  clslab-light-mixing-sparks-lab   4504  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_df = pd.DataFrame(sobol_points)\n",
    "result_df = pd.DataFrame(results)\n",
    "cat_df = pd.concat([param_df, result_df], axis=1)\n",
    "cat_df.to_csv(savepath, index=False)\n",
    "cat_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>utc_timestamp</th>\n",
       "      <th>background</th>\n",
       "      <th>ch470</th>\n",
       "      <th>ch410</th>\n",
       "      <th>ch440</th>\n",
       "      <th>sd_card_ready</th>\n",
       "      <th>ch510</th>\n",
       "      <th>ch550</th>\n",
       "      <th>ch670</th>\n",
       "      <th>utc_time_str</th>\n",
       "      <th>onboard_temperature_K</th>\n",
       "      <th>encrypted_device_id_truncated</th>\n",
       "      <th>logged_to_mongodb</th>\n",
       "      <th>ch620</th>\n",
       "      <th>device_nickname</th>\n",
       "      <th>ch583</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>1673316830</td>\n",
       "      <td>{'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...</td>\n",
       "      <td>3500</td>\n",
       "      <td>345</td>\n",
       "      <td>4826</td>\n",
       "      <td>True</td>\n",
       "      <td>1380</td>\n",
       "      <td>754</td>\n",
       "      <td>419</td>\n",
       "      <td>2023-1-10 02:13:50</td>\n",
       "      <td>293.6404</td>\n",
       "      <td>6307014457</td>\n",
       "      <td>False</td>\n",
       "      <td>11975</td>\n",
       "      <td>clslab-light-mixing-sparks-lab</td>\n",
       "      <td>7056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>1673316835</td>\n",
       "      <td>{'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...</td>\n",
       "      <td>11106</td>\n",
       "      <td>565</td>\n",
       "      <td>13474</td>\n",
       "      <td>True</td>\n",
       "      <td>8672</td>\n",
       "      <td>1456</td>\n",
       "      <td>822</td>\n",
       "      <td>2023-1-10 02:13:55</td>\n",
       "      <td>294.1085</td>\n",
       "      <td>6307014457</td>\n",
       "      <td>True</td>\n",
       "      <td>2754</td>\n",
       "      <td>clslab-light-mixing-sparks-lab</td>\n",
       "      <td>1710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1673316844</td>\n",
       "      <td>{'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...</td>\n",
       "      <td>1201</td>\n",
       "      <td>140</td>\n",
       "      <td>641</td>\n",
       "      <td>True</td>\n",
       "      <td>773</td>\n",
       "      <td>504</td>\n",
       "      <td>161</td>\n",
       "      <td>2023-1-10 02:14:04</td>\n",
       "      <td>294.1085</td>\n",
       "      <td>6307014457</td>\n",
       "      <td>True</td>\n",
       "      <td>6908</td>\n",
       "      <td>clslab-light-mixing-sparks-lab</td>\n",
       "      <td>4104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>1673316854</td>\n",
       "      <td>{'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...</td>\n",
       "      <td>3822</td>\n",
       "      <td>159</td>\n",
       "      <td>781</td>\n",
       "      <td>True</td>\n",
       "      <td>5996</td>\n",
       "      <td>954</td>\n",
       "      <td>230</td>\n",
       "      <td>2023-1-10 02:14:14</td>\n",
       "      <td>294.1085</td>\n",
       "      <td>6307014457</td>\n",
       "      <td>True</td>\n",
       "      <td>2191</td>\n",
       "      <td>clslab-light-mixing-sparks-lab</td>\n",
       "      <td>1358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>46</td>\n",
       "      <td>72</td>\n",
       "      <td>1673316864</td>\n",
       "      <td>{'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...</td>\n",
       "      <td>7841</td>\n",
       "      <td>500</td>\n",
       "      <td>11260</td>\n",
       "      <td>True</td>\n",
       "      <td>4111</td>\n",
       "      <td>1043</td>\n",
       "      <td>687</td>\n",
       "      <td>2023-1-10 02:14:24</td>\n",
       "      <td>294.1085</td>\n",
       "      <td>6307014457</td>\n",
       "      <td>True</td>\n",
       "      <td>7568</td>\n",
       "      <td>clslab-light-mixing-sparks-lab</td>\n",
       "      <td>4504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R   G   B  utc_timestamp  \\\n",
       "0  89  22  36     1673316830   \n",
       "1  27  87  84     1673316835   \n",
       "2  57  16   1     1673316844   \n",
       "3  26  66   5     1673316854   \n",
       "4  60  46  72     1673316864   \n",
       "\n",
       "                                          background  ch470  ch410  ch440  \\\n",
       "0  {'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...   3500    345   4826   \n",
       "1  {'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...  11106    565  13474   \n",
       "2  {'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...   1201    140    641   \n",
       "3  {'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...   3822    159    781   \n",
       "4  {'ch583': 32, 'ch670': 44, 'ch510': 75, 'ch410...   7841    500  11260   \n",
       "\n",
       "   sd_card_ready  ch510  ch550  ch670        utc_time_str  \\\n",
       "0           True   1380    754    419  2023-1-10 02:13:50   \n",
       "1           True   8672   1456    822  2023-1-10 02:13:55   \n",
       "2           True    773    504    161  2023-1-10 02:14:04   \n",
       "3           True   5996    954    230  2023-1-10 02:14:14   \n",
       "4           True   4111   1043    687  2023-1-10 02:14:24   \n",
       "\n",
       "   onboard_temperature_K  encrypted_device_id_truncated  logged_to_mongodb  \\\n",
       "0               293.6404                     6307014457              False   \n",
       "1               294.1085                     6307014457               True   \n",
       "2               294.1085                     6307014457               True   \n",
       "3               294.1085                     6307014457               True   \n",
       "4               294.1085                     6307014457               True   \n",
       "\n",
       "   ch620                 device_nickname  ch583  \n",
       "0  11975  clslab-light-mixing-sparks-lab   7056  \n",
       "1   2754  clslab-light-mixing-sparks-lab   1710  \n",
       "2   6908  clslab-light-mixing-sparks-lab   4104  \n",
       "3   2191  clslab-light-mixing-sparks-lab   1358  \n",
       "4   7568  clslab-light-mixing-sparks-lab   4504  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df = pd.read_csv(savepath)\n",
    "cat_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>onboard_temperature_K</th>\n",
       "      <th>ch410</th>\n",
       "      <th>ch440</th>\n",
       "      <th>ch470</th>\n",
       "      <th>ch510</th>\n",
       "      <th>ch550</th>\n",
       "      <th>ch583</th>\n",
       "      <th>ch620</th>\n",
       "      <th>ch670</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>293.6404</td>\n",
       "      <td>345</td>\n",
       "      <td>4826</td>\n",
       "      <td>3500</td>\n",
       "      <td>1380</td>\n",
       "      <td>754</td>\n",
       "      <td>7056</td>\n",
       "      <td>11975</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>294.1085</td>\n",
       "      <td>565</td>\n",
       "      <td>13474</td>\n",
       "      <td>11106</td>\n",
       "      <td>8672</td>\n",
       "      <td>1456</td>\n",
       "      <td>1710</td>\n",
       "      <td>2754</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>294.1085</td>\n",
       "      <td>140</td>\n",
       "      <td>641</td>\n",
       "      <td>1201</td>\n",
       "      <td>773</td>\n",
       "      <td>504</td>\n",
       "      <td>4104</td>\n",
       "      <td>6908</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>294.1085</td>\n",
       "      <td>159</td>\n",
       "      <td>781</td>\n",
       "      <td>3822</td>\n",
       "      <td>5996</td>\n",
       "      <td>954</td>\n",
       "      <td>1358</td>\n",
       "      <td>2191</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>46</td>\n",
       "      <td>72</td>\n",
       "      <td>294.1085</td>\n",
       "      <td>500</td>\n",
       "      <td>11260</td>\n",
       "      <td>7841</td>\n",
       "      <td>4111</td>\n",
       "      <td>1043</td>\n",
       "      <td>4504</td>\n",
       "      <td>7568</td>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>83</td>\n",
       "      <td>294.5767</td>\n",
       "      <td>495</td>\n",
       "      <td>13333</td>\n",
       "      <td>10100</td>\n",
       "      <td>6785</td>\n",
       "      <td>1196</td>\n",
       "      <td>448</td>\n",
       "      <td>637</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>78</td>\n",
       "      <td>294.5767</td>\n",
       "      <td>440</td>\n",
       "      <td>12403</td>\n",
       "      <td>8556</td>\n",
       "      <td>4538</td>\n",
       "      <td>956</td>\n",
       "      <td>824</td>\n",
       "      <td>1303</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>78</td>\n",
       "      <td>294.5767</td>\n",
       "      <td>439</td>\n",
       "      <td>12407</td>\n",
       "      <td>8556</td>\n",
       "      <td>4538</td>\n",
       "      <td>956</td>\n",
       "      <td>824</td>\n",
       "      <td>1303</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>24</td>\n",
       "      <td>67</td>\n",
       "      <td>54</td>\n",
       "      <td>294.5767</td>\n",
       "      <td>364</td>\n",
       "      <td>8069</td>\n",
       "      <td>7384</td>\n",
       "      <td>6295</td>\n",
       "      <td>1098</td>\n",
       "      <td>1296</td>\n",
       "      <td>2086</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>62</td>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>294.5767</td>\n",
       "      <td>508</td>\n",
       "      <td>9475</td>\n",
       "      <td>8485</td>\n",
       "      <td>7127</td>\n",
       "      <td>1346</td>\n",
       "      <td>4669</td>\n",
       "      <td>7853</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      R   G   B  onboard_temperature_K  ch410  ch440  ch470  ch510  ch550  \\\n",
       "0    89  22  36               293.6404    345   4826   3500   1380    754   \n",
       "1    27  87  84               294.1085    565  13474  11106   8672   1456   \n",
       "2    57  16   1               294.1085    140    641   1201    773    504   \n",
       "3    26  66   5               294.1085    159    781   3822   5996    954   \n",
       "4    60  46  72               294.1085    500  11260   7841   4111   1043   \n",
       "..   ..  ..  ..                    ...    ...    ...    ...    ...    ...   \n",
       "635   3  70  83               294.5767    495  13333  10100   6785   1196   \n",
       "636  16  50  78               294.5767    440  12403   8556   4538    956   \n",
       "637  16  50  78               294.5767    439  12407   8556   4538    956   \n",
       "638  24  67  54               294.5767    364   8069   7384   6295   1098   \n",
       "639  62  74  62               294.5767    508   9475   8485   7127   1346   \n",
       "\n",
       "     ch583  ch620  ch670  \n",
       "0     7056  11975    419  \n",
       "1     1710   2754    822  \n",
       "2     4104   6908    161  \n",
       "3     1358   2191    230  \n",
       "4     4504   7568    687  \n",
       "..     ...    ...    ...  \n",
       "635    448    637    738  \n",
       "636    824   1303    655  \n",
       "637    824   1303    655  \n",
       "638   1296   2086    533  \n",
       "639   4669   7853    693  \n",
       "\n",
       "[640 rows x 12 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cat_df.loc[:, [\"R\", \"G\", \"B\", \"onboard_temperature_K\"] + sdl.channel_names]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ch410', 'ch440', 'ch470', 'ch510', 'ch550', 'ch583', 'ch620', 'ch670']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdl.channel_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\numpy\\lib\\function_base.py:5071: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asarray(arr)\n"
     ]
    }
   ],
   "source": [
    "# pass the Dataframe as the data argument for Dataset and specify which one is the target variable\n",
    "dataset = Dataset(data=df, target_ids=sdl.channel_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `dataset` is an instance of the _Olympus_ class `Dataset`. However, before we can use it to train a custom `Emulator`, we need to specicify the parameter space for this dataset/problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olympus import ParameterSpace, Parameter\n",
    "\n",
    "# initialise a parameter space object\n",
    "param_space = ParameterSpace()\n",
    "\n",
    "# add all features in the dataset as a variable in the parameter space\n",
    "for feature in dataset.features:\n",
    "    low = np.min(dataset.data[feature])   # take the min in the data\n",
    "    high = np.max(dataset.data[feature])  # take the max in the data\n",
    "    param = Parameter(kind='continuous', name=feature, low=low, high=high)\n",
    "    param_space.add(param)\n",
    "    \n",
    "dataset.set_param_space(param_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above code we set the bounds of the parameters based on the min/max samples in the dataset. This can also be achieved by using the `infer_param_space` method of `Dataset`, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.infer_param_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, most often you will want these bounds to depend on the details your problem, in which case you can explicitly specify the bounds for all parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a small Bayesian Neural Network and we will test its performance in emulating this dataset. Note that, by default, `Dataset` creates 5 random folds for cross validation and reserves 20% of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olympus import Emulator\n",
    "from olympus.models import BayesNeuralNet\n",
    "\n",
    "mymodel = BayesNeuralNet(hidden_depth=2, hidden_nodes=12, hidden_act='leaky_relu', out_act=\"relu\", \n",
    "                         batch_size=50, reg=0.005, max_epochs=10000)\n",
    "emulator = Emulator(dataset=dataset, model=mymodel, feature_transform='normalize', target_transform='normalize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;37m[INFO] >>> Training model on 80% of the dataset, testing on 20%...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\tensorflow_probability\\python\\layers\\util.py:95: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  loc = add_variable_fn(\n",
      "c:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\tensorflow_probability\\python\\layers\\util.py:105: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  untransformed_scale = add_variable_fn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;37m[INFO]     =======================================================================\n",
      "\u001b[0m\u001b[0;37m[INFO]           Epoch       Train R2     Train RMSD        Test R2      Test RMSD\n",
      "\u001b[0m\u001b[0;37m[INFO]     =======================================================================\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (50,8) into shape (50,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m emulator\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\olympus\\emulators\\emulator.py:354\u001b[0m, in \u001b[0;36mEmulator.train\u001b[1;34m(self, plot, retrain)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[39m# Train\u001b[39;00m\n\u001b[0;32m    348\u001b[0m Logger\u001b[39m.\u001b[39mlog(\n\u001b[0;32m    349\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m>>> Training model on \u001b[39m\u001b[39m{0:.0%}\u001b[39;00m\u001b[39m of the dataset, testing on \u001b[39m\u001b[39m{1:.0%}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    350\u001b[0m         (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mtest_frac), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mtest_frac\n\u001b[0;32m    351\u001b[0m     ),\n\u001b[0;32m    352\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mINFO\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    353\u001b[0m )\n\u001b[1;32m--> 354\u001b[0m mdl_train_r2, mdl_test_r2, mdl_train_rmsd, mdl_test_rmsd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m    355\u001b[0m     train_features\u001b[39m=\u001b[39;49mtrain_features_scaled,\n\u001b[0;32m    356\u001b[0m     train_targets\u001b[39m=\u001b[39;49mtrain_targets_scaled,\n\u001b[0;32m    357\u001b[0m     valid_features\u001b[39m=\u001b[39;49mtest_features_scaled,\n\u001b[0;32m    358\u001b[0m     valid_targets\u001b[39m=\u001b[39;49mtest_targets_scaled,\n\u001b[0;32m    359\u001b[0m     model_path\u001b[39m=\u001b[39;49mmodel_path,\n\u001b[0;32m    360\u001b[0m     plot\u001b[39m=\u001b[39;49mplot,\n\u001b[0;32m    361\u001b[0m )\n\u001b[0;32m    363\u001b[0m \u001b[39m# write file to indicate training is complete and add R2 in there\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel_path\u001b[39m}\u001b[39;00m\u001b[39m/training_completed.info\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m content:\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\olympus\\models\\wrapper_tensorflow_model\\wrapper_tensorflow_model.py:159\u001b[0m, in \u001b[0;36mWrapperTensorflowModel.train\u001b[1;34m(self, train_features, train_targets, valid_features, valid_targets, model_path, plot)\u001b[0m\n\u001b[0;32m    154\u001b[0m losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[0;32m    156\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_int \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    157\u001b[0m \n\u001b[0;32m    158\u001b[0m     \u001b[39m# make a prediction on the validation set\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m     valid_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m    160\u001b[0m         features\u001b[39m=\u001b[39;49mvalid_features[valid_indices], num_samples\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    162\u001b[0m     valid_r2 \u001b[39m=\u001b[39m r2_score(valid_targets[valid_indices], valid_pred)\n\u001b[0;32m    163\u001b[0m     valid_rmsd \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(\n\u001b[0;32m    164\u001b[0m         mean_squared_error(valid_targets[valid_indices], valid_pred)\n\u001b[0;32m    165\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sterg\\Miniconda3\\envs\\sdl-demo\\lib\\site-packages\\olympus\\models\\wrapper_tensorflow_model\\wrapper_tensorflow_model.py:282\u001b[0m, in \u001b[0;36mWrapperTensorflowModel.predict\u001b[1;34m(self, features, num_samples)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_samples):\n\u001b[0;32m    279\u001b[0m         predic \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msess\u001b[39m.\u001b[39mrun(\n\u001b[0;32m    280\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_pred, feed_dict\u001b[39m=\u001b[39m{\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf_x: X_test_batch}\n\u001b[0;32m    281\u001b[0m         )\n\u001b[1;32m--> 282\u001b[0m         pred[_, start:stop] \u001b[39m=\u001b[39m predic[:size]\n\u001b[0;32m    284\u001b[0m pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(pred, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    285\u001b[0m \u001b[39mreturn\u001b[39;00m pred\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (50,8) into shape (50,1)"
     ]
    }
   ],
   "source": [
    "emulator.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now say you would like to share this dataset with the community by uploading it to the _Olympus Datasets_. You can do this with the `upload` command line tool in _Olympus_ as described in the documentation. However, you first need to prepare the dataset in the expected format. One way to easily do this is to use the `to_disk` method available to `Dataset` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to disk\n",
    "dataset.to_disk('custom_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json     data.csv        description.txt\n"
     ]
    }
   ],
   "source": [
    "!ls custom_dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdl-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "70cb6d4911b67e25d1487ebd620c5d1370239efaaf47f3851af44f5c5a26f988"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
